---
layout: post
title:  "The Start of an AI Journey"
date:   2023-05-16 21:35:09 -0000
categories: Artificial Intelligence
tags: [AI, ML, Artificial Intelligence, Machine Learning, tech, technology]
feature_image: images/ai-gen-mountain.jpeg

---
# Overview
Perhaps this post will age strangely but as of right now, fervor around artificial intelligence has reached an almost panicked pitch in society.  The unleashing of ChatGPT on the general public has caused complete mayhem from wild speculative investment to economic predictions both fanciful and apocalyptic to any manner of crime-adjacent activity (unconsenting porn, copyright infrignement, etc.).  I have only casually followed the AI field up until this point but have made the choice to follow the bandwagon (or more aptly, follow the white rabbit down the hole?).<!--more-->   As I descend, I thought it would be interesting to chart my course for future retrospection.  The reality is that there is a whole lot of noise and very little signal right now.  Perhaps when I arrive in whatever future AI brings, I'll be able to track how I got there!  For that reason, understand this post is written with me as its audience though I hope it is of use to you as well.

I've been investigating AI for a grand total of….3.5 months now.  I started this journey at the end of January with Nick Bostron's book: "Superintelligence: Paths, Dangers, Strategies" which I cannot recommend highly enough.  I will most certainly revisit it.  Relatedly, I cannot recommend enough to [read this list][reading_list] produced by Stanford's Human Centered AI group

## To put it in context, my studying so far has been:
* A few sessions at AWS Innovate Data and AI/ML
* Following a few AI subreddits 
* Reading everything I can off Corey Quinn's distribution email
* Playing around periodically with:
	* ChatGPT
	* Bard
	* several Character.AI engines
	* some fast-dreambooth
	* regular boring AI like If This Then That 
* Reading a bunch of books
    * Superintellingence: Paths, Dangers, Strategies by Nick Bostrom - Perhaps the best of all the books
	* Human Compatible, by Stuart Russell - Great!
	* Machines of Loving Grace: The Quest for Common Ground Between Humans and Robots, by John Markoff - Not great!
	* Life 3.0: Being Human in the Age of Artificial Intelligence, by Max Tegmark - Good!
	* Genius Makers, by Cade Metz - Great! 
	* The Alignment Problem, by Brian Cristian - Good!	

**So far, my impressions have been:**
1.  As with all things, the technology industry has overindexed on the impact of something novel and cool (think cryptocurrency and web 3.0) but it's still very misunderstood.
2.  AI is very advanced and advancing rapidly
3.  The rising of AI to general social awareness has produced an incredible array of new, awesome AI applications (but not advancements)
4.  We're probably not that close to AGI yet

### #1 
The technology industry has an incredible habit of taking very cool, very new tech and inferring from it an infinite set of stupid thoughts.  Perhaps it's just the earmark of a good tech to have an overactive imagination but when the industry invents something new, everyone goes full "Jojo the idiot circus boy" in making grand, uninformed proclamations about where this thing will certainly take us.  Even if you drop all the equally stupid naysayers so confidently predicting that 640kb of memory was the most we'd need (Bill Gates) or that the nuclear energy was not attainable (Albert Einstein), there are countless [examples of predictions of technology that were wrong][wrong_predictions].  People thought the internet would be primarily a weapons platform, some predicted mail would be delivered by rocket ship [(not a joke)][rocket_mail].  The common theme is that each time an admittedly groundbreaking tech entered the scene, someone stupidly oversimplified its effect and predicted with certainty something that turned out to be certainly wrong.  That's where we are right now in this [third AI spring][ai_spring].

Now, there are [countless reasons for this in psychology][psych_list] but ultimately, it doesn't matter too much to my point.  I know this round of AI innovation will and is making significant impact on society.  However, I don't think anyone knows what that means yet so I'm not attaching much to any prediction (and less to the confident ones).

### #2
AI is admittedly advancing very rapidly.  The actual technological breakthroughs that underlie AI are significant and impressive and arriving more quickly than any previous AI spring.  Looking only at the last 15 years of AI research, progress is much, much faster than the previous 60 years.  I'm particularly impressed with some emerging ideas:
* Learning is multi-faceted and AGI is likely leverage multiple types of learning to achieve AGI vs just a single AGI
* Neural networks are not only possible, they're probably essential to at least part of AGI
* Robotics and AI can go much farther than just robotics alone
* AI needs to be handled thoughtfully and safely

To be clear, here I'm separating out the advancements in actual AI vs in applications of AI (#3).  Realistically, these advancements have been in the works for a decade and are arriving kinda on time according to the experts.  However, they are not themselves single giant leaps.  ChatGPT LOOKS like a massive change but it simply represents a slowly, methodically assembled series of advancements by the OpenAI team.

### #3
The thing that is tripping most people up about AI is how rapidly it appears to be altering our lives.  There is no shortage of examples of AI being applied to search engines, home assistants and more.  There are programming buddies and foreign language tutors and AIs to generate any image you want.  However, they are mostly clever repackaging of admittedly cool AI underneath.  The advancements in the AI themselves have been developing for a decade (#2) but now that they are accessible to humans, we are finding incredibly ingenuous ways to use them.  Some are mistaking this for actual advanement.  Don’t get me wrong, we're still advancing but the hype is ahead of the promise and we will most likely enter another AI winter before AGI not from actual regression but from hype dying off.  Actually, it's more likely that AI will simply become less novel and it will SEEM like progress isn't being made.  So be it, the cool stuff is coming either way.

### #4
I am happy to see a growing awareness of the risks and dangers AI could bring.  There is endless writing on this point so I won't belabor them but I'm mostly concerned about the looming economic implications for unskilled humans that will need an income and for the potential for AI to be integrated in weapons systems.  There are many more and all are valid but again, that's a post on its own. 

I will simply say that I personally think the often proposed tactic of simply taking it slow is actually wrong (sorry Nick!).  I think AI is so winner-take-all that we must proceed at a breakneck pace until we achieve AGI and we simply need to have parallel breakneck speed on safety.  Slowing to catch saftey up risks less safe actors getting their first so we simply have no choice but to go fast and safe at the same time.

[wrong_predictions]: https://www.hero-labs.com/stories/the-22-worst-tech-predictions-of-all-time/
[reading_list]: https://hai.stanford.edu/news/ai-book-recs-add-these-your-reading-list
[psych_list]: https://www.theatlantic.com/science/archive/2017/11/humans-are-bad-at-predicting-futures-that-dont-benefit-them/544709/ 
[ai_spring]: https://en.wikipedia.org/wiki/AI_winter
[rocket_mail]: https://www.hero-labs.com/stories/the-22-worst-tech-predictions-of-all-time/